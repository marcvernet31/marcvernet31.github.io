<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Marc Vernet</title>
        <link>https://marcvernet31.github.io/posts/</link>
        <description>Recent content in Posts on Marc Vernet</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Sun, 24 Jan 2021 16:43:53 +0100</lastBuildDate>
        <atom:link href="https://marcvernet31.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Bicing Visualizations</title>
            <link>https://marcvernet31.github.io/posts/2021/01/bicing-visualizations/</link>
            <pubDate>Sun, 24 Jan 2021 16:43:53 +0100</pubDate>
            
            <guid>https://marcvernet31.github.io/posts/2021/01/bicing-visualizations/</guid>
            <description>The aim of this project was to develop two sets of insightful visualizations for the Bicing Data, Barcelona bike sharing service, to compare performance characteristics of differne stations and kinds of bikes (mechanical and electric). Both groups of visualizations were developed with Python&amp;rsquo;s library Altair.
The first visualization consisted of a static infographic, comparing the usage of two docking stations during January 2020. The infographic was designed to show the performance differences of two stations with opposite characteristics.</description>
            <content type="html"><![CDATA[<p>The aim of this project was to develop two sets of insightful visualizations for the Bicing Data, Barcelona bike sharing service, to compare performance characteristics of differne stations and kinds of bikes (mechanical and electric). Both groups of visualizations were developed with Python&rsquo;s library <strong>Altair</strong>.</p>
<p>The first visualization consisted of a static infographic, comparing the usage of two docking stations during January 2020. The infographic was designed to show the performance differences of two stations with opposite characteristics.</p>
<p>The two compared stations where <a href="https://www.google.es/maps/place/Bicing/@41.3747764,2.1869208,16.82z/data=!4m5!3m4!1s0x12a4a3c6538cf687:0x51d2bb55fb45be6b!8m2!3d41.3747999!4d2.1889045?hl=ca&amp;authuser=0">Station 31</a>, at sea level and <a href="https://www.google.es/maps/place/Bicing/@41.4048552,2.1344278,18z/data=!4m8!1m2!2m1!1sbicing+327!3m4!1s0x0:0xe4370e7632ee268d!8m2!3d41.405008!4d2.1346039?hl=ca&amp;authuser=0">Station 327</a> at the mountain.
At mountain level stations there&rsquo;s high demand of bikes, because all the routes are downhill. However, at sea level many people arrive with bike, but there&rsquo;s not a high demand for bikes. This causes during peak hours a deficit of bikes in mountain stations and a deficit of free docking space at sea level stations.<br>
<br>
<br>

    <img src="/img/plot.png"  alt="plot"  class="center"  style="border-radius: 5px;   width: 1200px;"  />


<br>
<br>
The second visualization is a set of interactive plots, showing the performance of all Barcelona stations during January 2020. The aim of this more complex visualization was on one hand to show an &ldquo;overview&rdquo; of the whole Bicing service and on the other hand to allow the user access specific information under request.
With the use of <strong>Altair</strong>  interactive capabilities, more information can be shown in an intuitive way, making it easier for the user to understand the data and find meaningful relations.
<br>
<br>

    <img src="/img/map.png"  alt="Hello Friend"  class="center"  style="border-radius: 5px;   width: 800px;"  />


<br>
<br>
This project was developed in the context of <a href="https://www.fib.upc.edu/en/studies/bachelors-degrees/bachelor-degree-data-science-and-engineering/curriculum/syllabus/VI-GCED">VI -GCED</a> class, as a way to implement both theoretical and practical knowledge learnt during the course. All the visualizations were designed with a strong focus on technical quality principles such as <em>Schneiderman&rsquo;s mantra</em> and the <em>laws of perception</em>.</p>
<p>Both visualizations are implemented in Collab ipynb notebooks. In the notebooks all the design process, decisions and final result are detailed (in Catalan). It can all be found in <a href="https://github.com/marcvernet31/Bicing-Visualization">this repository</a>.</p>
]]></content>
        </item>
        
        <item>
            <title>Kernel methods on cannabis microsatellite data</title>
            <link>https://marcvernet31.github.io/posts/2021/01/kernel-methods-on-cannabis-microsatellite-data/</link>
            <pubDate>Thu, 14 Jan 2021 17:48:24 +0100</pubDate>
            
            <guid>https://marcvernet31.github.io/posts/2021/01/kernel-methods-on-cannabis-microsatellite-data/</guid>
            <description>This project was developed with the goal to study in which way kernel functions could better prediction results, and discover ways to fine-tune custom functions in order to to maximize the performance.
This work was done in the context of AA2 UPC class final project, oriented to kernel methods. Most of the work was done with Python&amp;rsquo;s sklearn and R for preprocessing.
The final report with conclusions and interactive notebooks with used code can be found at the github repository.</description>
            <content type="html"><![CDATA[<!-- raw HTML omitted -->
<p>This project was developed with the goal to study in which way kernel functions could better prediction results, and discover ways to fine-tune custom functions in order to to maximize the performance.</p>
<p>This work was done in the context of <a href="https://www.fib.upc.edu/en/studies/bachelors-degrees/bachelor-degree-data-science-and-engineering/curriculum/syllabus/AA2-GCED">AA2 UPC</a> class final project, oriented to kernel methods. Most of the work was done with Python&rsquo;s <strong>sklearn</strong>  and <strong>R</strong> for preprocessing.</p>

    <img src="/img/families.png"  alt="Hello Friend"  class="center"  style="border-radius: 5px;   width: 300px;"  />


<p>The final report with conclusions and interactive notebooks with used code can be found at the <a href="https://github.com/marcvernet31/Project-Kernel">github repository</a>.</p>
<!-- raw HTML omitted -->
]]></content>
        </item>
        
        <item>
            <title>Predictive Analytics with Big Data Tecnologies</title>
            <link>https://marcvernet31.github.io/posts/2021/01/predictive-analytics-with-big-data-tecnologies/</link>
            <pubDate>Thu, 07 Jan 2021 17:40:52 +0100</pubDate>
            
            <guid>https://marcvernet31.github.io/posts/2021/01/predictive-analytics-with-big-data-tecnologies/</guid>
            <description>The objective of this project was the creation of a distributed ETL data flow for an aviation maintenance business case. The original dataset is a set of maintenance and flight data from a real airline (AIMS and AMOS extracted data), and the goal was cleaning the data and extracting the necessary KPI&amp;rsquo;s in order to train a model to predict whether maintenance was required for a specific airplane.
All code was done having distribution in mind, with Python and Spark API, pyspark.</description>
            <content type="html"><![CDATA[<!-- raw HTML omitted -->
<p>The objective of this project was the creation of a distributed ETL data flow for an aviation maintenance business case. The original dataset is a set of maintenance and flight data from a real airline (<a href="https://aerospace.honeywell.com/en/learn/products/cockpit-systems-and-displays/airplane-information-management-system">AIMS</a> and <a href="https://www.swiss-as.com/amos-mro">AMOS</a> extracted data), and the goal was cleaning the data and extracting the necessary KPI&rsquo;s in order to train a model to predict whether maintenance was required for a specific airplane.</p>
<p>All code was done having distribution in mind, with Python and Spark API, <strong>pyspark</strong>.  Prediction was done with <strong>mllib</strong>.</p>
<p>The final result is a script that can be executed with a terminal, that is capable of training a model with data extracted online and predict on-demand with user input data and different configurable characteristics</p>
<p>The code developed and extra information on how to use the tool can be found at this <a href="https://github.com/marcvernet31/Spark---BDA">github repository</a>.</p>
<!-- raw HTML omitted -->
]]></content>
        </item>
        
        <item>
            <title>Distributed Systems</title>
            <link>https://marcvernet31.github.io/posts/2020/07/distributed-systems/</link>
            <pubDate>Wed, 22 Jul 2020 12:59:03 +0100</pubDate>
            
            <guid>https://marcvernet31.github.io/posts/2020/07/distributed-systems/</guid>
            <description>This projects where developed for the PSD-GCED class as a way to learn about distributed computing environments.
The first project was oriented on learning to work in HPC (High Performance Computing) distributed environments. We where given access to the MareNostrum supercomputer with the aim to create and execute scripts to run the NAS Parallel Benchmarks with different configurations. The scripts and final report can we found here.
The second project objective was to learn to work with cloud providers, taking advantage of its distributed capabilities.</description>
            <content type="html"><![CDATA[<p>This projects where developed for the <a href="https://www.fib.upc.edu/en/studies/bachelors-degrees/bachelor-degree-data-science-and-engineering/curriculum/syllabus/PSD-GCED">PSD-GCED</a> class as a way to learn about distributed computing environments.</p>
<p>The first project was oriented on learning to work in HPC (High Performance Computing) distributed environments. We where given access to the <a href="https://en.wikipedia.org/wiki/MareNostrum">MareNostrum</a> supercomputer with the aim to create and execute scripts to run the <a href="https://en.wikipedia.org/wiki/NAS_Parallel_Benchmarks">NAS Parallel Benchmarks</a> with different configurations. The scripts and final report can we found <a href="https://github.com/marcvernet31/Proyecto-HPC">here</a>.</p>
<p>The second project objective was to learn to work with cloud providers, taking advantage of its distributed capabilities. The goal was to extract twitter analytic information with the twitter API and processing it using <strong>Spark</strong>, distributed in several <strong>AWS EC2</strong> machines. The resulting report and code can be found <a href="https://github.com/marcvernet31/Spark-AWS">here</a>.</p>
]]></content>
        </item>
        
        <item>
            <title>Telegram Bicing bot</title>
            <link>https://marcvernet31.github.io/posts/2019/07/telegram-bicing-bot/</link>
            <pubDate>Wed, 03 Jul 2019 10:47:08 +0100</pubDate>
            
            <guid>https://marcvernet31.github.io/posts/2019/07/telegram-bicing-bot/</guid>
            <description>TheRealBicingBot, is a Telegram bot capable of retrieving real time information of the Bicing service. Bicing is the Barcelona bike sharing service. It is concieved as a way to help maintenance workers keep of a good bike distribucion among the different city areas.
The application is used via direct chat with the bot. The network of stations is modeled as a graph, that is created on demand based on user input specifications.</description>
            <content type="html"><![CDATA[<p>TheRealBicingBot, is a Telegram bot capable of retrieving real time information of the Bicing service. Bicing is the Barcelona bike sharing service.
It is concieved as a way to help maintenance workers keep of a good bike distribucion among the different city areas.</p>
<p>The application is used via direct chat with the bot. The network of stations is modeled as a graph, that is created on demand based on user input specifications.
The bot is capable of calculating fastest routes between origin and destination points, printing a map with the path. It&rsquo;s also capable of calculating the redistribution of bikes, given the number of required bikes per station returns the cost of doing a transaction to solve it.</p>

    <img src="/img/bicing.png"  alt="Hello Friend"  class="center"  style="border-radius: 5px;   width: 350px;"  />


<p>The bot was developed with <strong>Python</strong>,  the <strong>NetworkX</strong> library was used to model the graph and <strong>StaticMap</strong> to plot the maps.</p>
<p>TheRealBicingBot was developed as a final project for <a href="https://www.fib.upc.edu/en/studies/bachelors-degrees/bachelor-degree-data-science-and-engineering/curriculum/syllabus/AP2-GCED">AA2-GCED</a> class. The complete code, with more detailed documentation and testing functions can be found at this <a href="https://github.com/marcvernet31/BicingBot">github repository</a> (in Catalan).</p>
]]></content>
        </item>
        
        <item>
            <title>Polygon Calculator</title>
            <link>https://marcvernet31.github.io/posts/2019/01/polygon-calculator/</link>
            <pubDate>Fri, 04 Jan 2019 11:56:42 +0100</pubDate>
            
            <guid>https://marcvernet31.github.io/posts/2019/01/polygon-calculator/</guid>
            <description>Polygon Calculator is a C++ program that provides an intuitive and easy way of doing different calculus related to polygon geometry from the computer terminal.
The user can input polygons as a set of points, and calculate metrics such as area or perimeter. Multiple polygons can be inputed, so it&amp;rsquo;s possible to generete intersections and bounding boxes.
All results can be saved in a .txt file and loaded again. The program also supports plotting inputed polygons and results in a .</description>
            <content type="html"><![CDATA[<p>Polygon Calculator is a <strong>C++</strong> program that provides an intuitive and easy way of doing different calculus related to polygon geometry from the computer terminal.</p>
<p>The user can input polygons as a set of points, and calculate metrics such as area or perimeter. Multiple polygons can be inputed, so it&rsquo;s possible to generete intersections and bounding boxes.</p>
<p>All results can be saved in a <code>.txt</code> file and loaded again.  The program also supports plotting inputed polygons and results in a <code>.png</code> image, with the <strong>pngwritter</strong> library. All code is created with optimization in mind, using several complex algorithms to keep computational costs low.</p>
<p>This project was developed for <a href="https://www.fib.upc.edu/en/studies/bachelors-degrees/bachelor-degree-data-science-and-engineering/curriculum/syllabus/AP2-GCED">AA2-GCED</a> class, as a way of testing C++ and algorithm knowledge learnt during the course. The complete code and extensive documentation can be found at this <a href="https://github.com/marcvernet31/Polygon-Calculator">github repository</a>.</p>
]]></content>
        </item>
        
    </channel>
</rss>
